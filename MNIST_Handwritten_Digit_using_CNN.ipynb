{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Convolution is simply mathematical operation on 2 function"
      ],
      "metadata": {
        "id": "aGiWvoaI3gyE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTvNVY6f1oaQ"
      },
      "outputs": [],
      "source": [
        "1. Every image is made of pixels that range from 0 to 255\n",
        "2. We need to convert first into a range of 0 to 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Components of convolution:\n",
        "1. Feature extraction: various filters & layers are applied\n",
        "2. Classification : classified based on target variable"
      ],
      "metadata": {
        "id": "FHhg_Ejo4U9z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolution layer**"
      ],
      "metadata": {
        "id": "mRvjTccU_Emk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Convolution layer => layer where the filter is applied to input image to extract/detect its features and feature map is created\n",
        "2. Filter is shifted by 1 col ie Stride =>+ shifting by 1/2\n",
        "3. we get feature map and then apply activation func (sum of input is tranformed into output)"
      ],
      "metadata": {
        "id": "VL9RfAwj8tMn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pooling Layer**"
      ],
      "metadata": {
        "id": "B9CgFntw-_4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Reduce the dimensions of feature maps (preserves imp feature)\n",
        "2. Convert input image to lower resolution version\n",
        "3. Max pooling & average pooling : types\n",
        "4. Max pooling : selects brighter pixels from image useful when bg is dark and we are only interested in lighter pixels\n",
        "5. Avg pooling : smooth out image & sharp features may not be identified"
      ],
      "metadata": {
        "id": "ic2uUrEa-wYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fully Connected Layer**"
      ],
      "metadata": {
        "id": "7TnO2ADFB126"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1. Now classification starts\n",
        "2. FLC expects 1d vector of nos\n",
        "3. We flatten the output (2d to 1d)"
      ],
      "metadata": {
        "id": "ddxZAQZ9AH5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST Handwritten Digit data"
      ],
      "metadata": {
        "id": "TMb01SpcCQEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential # build model layer by layer\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout"
      ],
      "metadata": {
        "id": "gNWXp42ZCPmI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ],
      "metadata": {
        "id": "AtR12-LRBJll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "_JqgQ8BhA7Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abc02b4d-89fb-4499-f3ec-6b9cc32cecb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping the data"
      ],
      "metadata": {
        "id": "p7WAoCuTBNO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\n",
        "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1))"
      ],
      "metadata": {
        "id": "DaCE4yjmBHr9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the shape after reshaping"
      ],
      "metadata": {
        "id": "VLIvoHEw1yxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "mR_FCeAjBq-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810dd13e-d1a6-45f6-8db5-6cdd1b623af8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalising the pixel values"
      ],
      "metadata": {
        "id": "31zI6fa41623"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "lApgtFQC15JA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this X_train & X_test will contain images\n",
        "# print(X_train)\n",
        "# print(X_test)\n",
        "\n",
        "# this y_train & y_test will contain digits that image represent"
      ],
      "metadata": {
        "id": "hf4aOCa22DaJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "FcClA43O2HUE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Layer"
      ],
      "metadata": {
        "id": "58VC3AtQBRYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)))\n",
        "# input image size = 28,28 and 1 is for grayscale"
      ],
      "metadata": {
        "id": "-OnpkQW-4428"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max Pooling Layer"
      ],
      "metadata": {
        "id": "LwRFMmyJAucL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(MaxPool2D(2,2))\n",
        "# max value will be taken from 2*2 matrix"
      ],
      "metadata": {
        "id": "nPmGc282AksF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fully Connected Layer"
      ],
      "metadata": {
        "id": "LmRppw-WBPEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Flatten())\n",
        "model.add(Dense(100,activation='relu'))"
      ],
      "metadata": {
        "id": "y_2IF2amA68p"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding output layer\n",
        "model.add(Dense(10,activation='softmax') )\n",
        "# adding another dense layer of 10 nuerons so we use softmax\n",
        "# output is probablistic\n",
        "# the model will then make prediction based on the option that has highest probability"
      ],
      "metadata": {
        "id": "tcSM-CyHBZmp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1. We will sparse categorical cross entropy\n",
        "instead of binary cross entropy loss func => as this a categorical problem"
      ],
      "metadata": {
        "id": "wkbAcHJwBJQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2CTG9IuKDPkm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the model"
      ],
      "metadata": {
        "id": "HQnA9WRQDuO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v-5z4gsDmLV",
        "outputId": "b6b34731-c14a-4714-9bad-e3df042127cc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 102s 54ms/step - loss: 1.8221 - accuracy: 0.3731\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 102s 54ms/step - loss: 1.2100 - accuracy: 0.4895\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 102s 55ms/step - loss: 1.0176 - accuracy: 0.5228\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 104s 55ms/step - loss: 0.8186 - accuracy: 0.6073\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 102s 54ms/step - loss: 0.6754 - accuracy: 0.6881\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.5670 - accuracy: 0.7064\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 106s 57ms/step - loss: 0.5286 - accuracy: 0.7115\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.4330 - accuracy: 0.7994\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 105s 56ms/step - loss: 0.2987 - accuracy: 0.8683\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 101s 54ms/step - loss: 0.1923 - accuracy: 0.8951\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c225b261b70>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAPnySIRDzVX",
        "outputId": "a86f8eb3-773f-40a0-884f-a0c8cb0ca9b2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 14ms/step - loss: 0.2149 - accuracy: 0.8938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21494066715240479, 0.8938000202178955]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJDKkGzcHyoY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}